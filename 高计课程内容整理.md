# 2020高计课程内容整理

*by C.D.N., edited with Typora*



## 0219 回归概念与预备知识

- 随机现象、概率、新息集、（离散型和连续型）随机变量、分布函数

- p维随机向量的边缘分布与联合分布、边缘概率密度函数



## 0226 多元变量

- 边缘概率密度函数和联合概率密度函数
- 多元正态分布$N(0,\Sigma)$，p维向量服从正态分布的充要条件
- ==**多元线性回归模型**==、多元随机向量的==**协方差矩阵**==$Cov(X,Y)=E((X-EX)(Y-EY)^\top)$，$X$的方差矩阵$Var(X)=E((X-EX)(X-EX)^\top)$
  - $Cov(X,Y)$协方差矩阵实际上是各分量协方差的 $p\times q$ 矩阵。$(i,j)$ 位置的元素是 $Cov(X_i, Y_j)$，可以研究不同市场的相关关系
  - $Var(X)=(Cov(X_i, X_j)_{p\times p}).$，其主对角线元素是每个经济指标的波动（风险），非对角线元素衡量两个经济指标间的相关关系
- 条件分布函数 $F_{Y|X}(y|x)=F_{X,Y}(x,y)/F_X(x)$.，生存分析函数 $S_{Y|X}(y|x)=1-F_{Y|X}(y|x)$，若干性质



## 0304  更多证明

- 条件边缘分布与条件联合分布的关系、多元随机向量的条件边缘概率密度函数、多元随机向量的条件期望和条件矩
- 期望符号拿进向量符号内的证明（离散型/连续型）
- 条件协方差矩阵$Cov(Y,Z|X=x)=E((Y-E(Y|X=x)(Z-E(Z|X=x)^\top))$​，反映经济指标的条件相关关系
- 依分布收敛和几乎处处收敛
- Kolmogorov强大数律



## 0311 更多证明

- 中心极限定理的两种形式，理论证明
- 矩阵的逆、可逆条件、正定/负定/非正定/非负定充要条件、特征根等线代内容
- ==**<第二章>**== 多元线性回归模型，回归函数、回归模型



## 0318 多元线性回归模型与最小二乘法

- 线性回归模型，非线性回归模型（广义、非参数、半参数）

- 使用泰勒公式，多元线性回归模型可以用来逼近非直线系统。

- 识别性和内生性

  - 解释变量之间不应该存在相关性：$Cov(x_i, x_j)=0, E(x)=0$
  - 第$j$个经济指标的斜率参数恰好等于被解释变量$y$和解释变量$x_j$的相关系数：$\beta_j=Cov(y, x_j)/\sigma_{x_j}^2=\rho(y, x_j)$
  - 提到了三因子模型

- 多元线性回归模型的估计：估计$\beta_0, ..., \beta_k$的$k+1$个未知参数和市场干扰$\sigma^2$，一共$k+2$个待估计参数。

  - 随机干扰的分布假设，假定$\varepsilon|x \sim N(0,\sigma^2)$

  - 线性回归方程组，$I_n$为n阶单位矩阵
    $$
    Y=X\beta+v \\
    E(v|X)=0, v=(\varepsilon_1, ...,\varepsilon_n)^\top \\
    v|X \sim N(0, \sigma^2I_n),\ \sigma>0
    $$

- 求解线性回归参数：矩阵微分方法

  - 对向量求偏导、矩阵与向量参数成绩的积分
  - 多元线性回归模型参数的最小二乘估计，Gauss的最小二乘法，广义逆矩阵的定义
  - 二次损失函数$L(\beta)=v^\top v/n$，找到一个$\hat \beta$使得二次损失函数达到最小。

- $\beta$ 的最小二乘解满足 $\hat \beta = \arg \{ \min \limits_{\beta \in R^{k+1}}L(\beta)\}= \arg \{ \min \limits_{\beta \in R^{k+1}}(Y-X\beta)^\top(Y-X\beta)\}$



## 0325 线性模型的解

- 线性方程组有解的充要条件，存在唯一解时$rank(X)=k+1, \hat \beta=(X^\top X)^{-1}X^\top Y.$

  - 此时 $\hat \beta$ 是 $\beta$ 的误差平方和最小的无偏估计、极大似然估计、强有效估计。（有证明）
  - $\hat \beta$ 的正态性：$\hat \beta - \beta \sim N(0, (X^\top X)^{-1}\sigma^2).$

- 根据最小二乘原理和样本数据，求解二次优化 $\min \limits_{\beta \in R} \sum^n_{i=1} \varepsilon_i^2$ 的解称为最小二乘法。

- **k元线性回归模型**
  $$
  y=\tilde x^\top \beta + \varepsilon, \\
  E(\varepsilon|x)=0, \ Var(\varepsilon|x)=\sigma_\varepsilon(x^2) > 0
  $$

- 识别性问题：如果模型可通过无限次试验找到其唯一真实参数，它是可识别的。如果在特定约束条件下模型可识别，该约束为可识别条件。

  - 假设$E(x^\top x)>0$，则可识别的唯一解满足$\beta=(E(\tilde x \tilde x^\top))^{-1}E(\tilde x y).$



## 0401 识别问题与复相关分析

- 在$E(x^\top x)$不满秩的情况下的可识别性的问题。
- **误差分布未知**情况下，多元线性回归模型的参数估计
  - 可识别条件下 $\hat \beta = (X^\top X)^{-1}X^\top Y$. 此时 $\hat \beta$ 是 $\beta$ 的误差平方和达到最小的无偏估计、强有效估计
  - $\hat \beta$ 具有渐近正态性。$\sqrt n (\hat \beta - \beta)=\sqrt n (X^\top X)^{-1} \stackrel{d}{\rightarrow}N(0, \sigma^2(E(x^\top x)^{-1})), n\rightarrow \infin.$
  - 可得 $(X^\top X)^{1/2}(\hat \beta - \beta)/\sigma \stackrel{d}{\rightarrow} N(0, I_{k+1}), n\to \infin. $

- 实际应用中：==**检验能否用该模型拟合样本数据**==

- 多元线性模型的复相关分析
  - 向量的相关分析称为复相关分析。
  - 由Kolmogrov强大数律，$R\to \rho(X,Y) a.s. n\to \infin$.

$$
R=\frac{\sum\limits^n_{i=1}(X_i-\bar X)(Y_i-\bar Y)}{\sqrt{\sum\limits^n_{i=1}(X_i-\bar X)^2\sum\limits^n_{i=1}(Y_i-\bar Y)^2}}
$$



## 0408 复相关系数与方差分析

- 复相关系数的定义，若干矩阵计算（分块求逆）。

  $$
  L_{xx}=\sum^n_{i=1}(X_i-\bar X)(X_i-\bar X)^\top, k\times k
  \\ L_{yy}=\sum^n_{i=1}(y_i-\bar Y)^2, 
  \\ L_{xy}=\sum^n_{i=1}(X_i-\bar X)(y_i-\bar Y), k \times 1
  \\ L_{yx}=\sum^n_{i=1}(y_i-\bar Y)(X_i-\bar X)^\top. 1\times k
  $$

  

  - 其中 $X$ 是矩阵，而 $y$ 是向量，$L_{xy}=(L_{yx})^\top$.

  - 复相关系数 $R_n^2=L_{yx}L_{xx}^{-1}L_{xy}L_{yy}^{-1}$

- 方差分析
  $$
  S_{total}=\sum\limits^n_{i=1}(y_i-\bar Y)^2 
  \\S_{res}=\sum\limits^n_{i=1}(\hat y_i-y_i)^2 
  \\S_{reg}=\sum\limits^n_{i=1}(\hat y_i - \bar Y)^2 
  \\ \hat Y=X \hat \beta 
  \\ R_n^2=\frac{S_{reg}}{S_{total}}
  $$

  - 当 $rank(X)=k+1$ 时，$S_{total}=S_{res}+S_{reg}$.

- 带有正态误差的标准线性模型

  - 投影矩阵方法，$P_X=X(X^\top X)^{-1}X^\top, P_X^2=P_X$
  - 性质$u\in S(X), P_X u=u,\ v\in L(X),P_Xv=0.$ $R^n=S(X)+L(X), t\in R^n, t=u+v, P_Xt=P_Xu=u$
  - $\hat Y=P_X Y$，是 $Y$ 在 $X$ 的垂直投影



## 0415 假设检验统计量的构造（$F, t, R^2$）

- **第一个问题：所有的 $\beta$ 不全为0。**检验统计量的构造：**F 统计量**
  $$
  E[Y|X]=X\beta, \\
  Y-X\beta \sim N(0, \sigma^2 I_n), \\
  \frac{(Y-X\beta)^\top(Y-X\beta)}{\sigma^2} \sim \chi^2(n), \\
  F=\frac{S_{reg}/k}{S_{res}/(n-k-1)}=\frac{ \frac{\sum\limits^n_{i=1}(\hat y_i - \bar Y)^2/\sigma^2}{k}}{\frac{\sum\limits^n_{i=1}(\hat y_i-y_i)^2/\sigma^2}{n-k-1}},
  \ \  F\ stat.
  $$
  - 如果零假设成立，Y和X满足线性回归模型，（具体因果关系参考PPT）F统计量则较大，可以作为检验统计量

- F 统计量的性质和分布
  - 零假设成立时，可以简化求得对应的$S_{reg}\ \& \ S_{res}$，进而可以求得 F 统计量的阈值
  - 可知两项方差的分布 $S_{reg}/\sigma^2 \sim \chi^2(k), \ S_{res}/\sigma^2 \sim \chi^2(n-k-1) .$
  - 从而由定义可知 F 统计量的分布 $F \sim F(k, n-k-1)$.
  - 拒绝域的构造方法
- **第二个问题，第 $i$ 个系数 $\beta_i$ 不为0。**检验统计量构造：**T 统计量**
  
  - 具体证明见视频/PPT
- **第三个问题，x和y是否存在线性相关关系。**检验统计量的构造：$R^2$

$$
R^2 = \frac{S_{reg}}{S_{total}}=\frac{S_{reg}}{S_{reg}+S_{res}}=\frac{\frac{k}{n-k-1}F(k, n-k-1)}{\frac{k}{n-k-1}F(k, n-k-1)+1}
$$



## 0422 变量的添加与剔除

- 解决添加或者剔除变量的问题，可以使用 t 统计量和 F 统计量进行考察。
  - 添加变量：添加$X_{k+1}$，$F_{k+1}=T_{k+1}^2 \sim F(1, n-k-2)$ ，大于给定置信水平 $F_\alpha(1, n-k-2)$ 即可添加。
  - 剔除变量：剔除$X_k$，找到最小的 $F_k(k)$ 且小于给定置信水平 $F_\alpha(1, n-k-1)$ 即可剔除。
- 变量筛选法：向前引入法、向后剔除法、双重逐步筛选法
  - 向前引入法：相关系数降序排列后，逐个添加并检验待添加变量，直到没有可以添加的为止。
  - 向后剔除法：找到最不能拒绝 $H_0$ 的变量剔除，并继续检验其它的能否剔除，直到没有可以剔除的为止。
  - 双重逐步筛选法：交替使用，每次向前引入后都要向后剔除一个。



## 0429 逐步筛选和模型诊断介绍

- 逐步筛选法的流程
  - 确定两个临界值：引入第 $i$ 个变量的标准 $F_{a,i}$ 和第 $i$ 个变量入选后剔除的标准 $F_{b,i}$.
  - 引入变量时，计算待引入变量的 $\max F_i$，若 $\max F_i \geq F_{a,i}$，则可以引入对应的$x_i$。
  - 计算此时所有变量的 $\min F_i$，若 $\min F_i \leq F_{b,i}$，则剔除对应的$x_i$。

- ==**逐步回归**==：对逐步筛选法选取的变量进行回归。
  - 逐步回归法可以在一定程度上避免==**多重共线性问题**==，多重共线性问题导致不可识别或过度识别。
  - 如果两个变量具有高度相关，那么其中一个通过逐步筛选选中后，另一个则不可能通过筛选。
- ==**模型诊断**==初步介绍：广义的线性模型的转换
  - 不满足线性模型时，可以通过数据的变换进行转化。
  - 回归函数具有三阶连续偏导，可以使用泰勒展式 $y=m(X)+\varepsilon=\beta_0+\sum^p_{i=1}u_i\beta_i+\varepsilon$，其中$\{u_i\}$包含$X$的直至四次项的全部项。
  - 对数增长模型。$z_t=\ln(y_t/y_{t-1}),z_t=\beta_0+\sum^k_{i=1}\beta_i \ln(x_{t,i}/x_{t-1,i})+e_t, 2\leq t \leq n$. 可以得到线性模型$Z=H\beta+\varepsilon, \varepsilon|X_{(n)} \sim N(0,\sigma^2I_n)$. 其中$H=(1_nH_n)$，$H_n$是$(\ln(\frac{\Delta x_{i+1,j}}{x_{i,j}}))_{i\times j}$



## 0506 线性回归的残差分析

- 对于标准的多元回归模型，含有一些隐含条件：
  $$
  \varepsilon_1, ..., \varepsilon_n \ i.i.d \\
  \varepsilon_t | X_t \sim N(0, \sigma^2), 1\leq t \leq n.
  $$
   这些条件成立时，LSE估计量$\hat\beta$具有很好的性质，但是这些假设不成立时，性质也不一定成立，F 统计量和 t 统计量也不一定再服从 F 分布和 t 分布。

- 主要的诊断工具是==**残差分析**==。$\hat Y=X\hat \beta=P_X Y, \hat \varepsilon = Y-\hat Y$. 令 $P_X=(h_{ij})_{n\times n}$，则 $\hat y_i=\sum\limits ^n_{j=1}h_{ij}y_j, 1\leq i\leq n$.

  - 如果 $\varepsilon \sim N(0,\sigma^2I_n)$ 中的 $\sigma$ 已知，则可以构建统计量 $\sum\limits^n_{i=1}\hat \varepsilon_i^2 / \sigma^2$，如果 $\sum\limits^n_{i=1}\hat \varepsilon_i^2 / \sigma^2 > \chi_\alpha$，则拒绝原假设。
  - 如果 $\sigma$ 未知，构建统计量$Z_{n,j}=\hat \varepsilon_j / \sqrt {1-h_{jj}} / \sqrt {S_{res}/(n-k-1)}$ ，近似服从标准正态分布。
  - 随机干扰独立性诊断：游程检验，德宾DW检验，JB/LB检验
    - DW统计量（略，见PPT/视频），似乎可以将随机干扰序列认为是$AR(1)$，从而去除一阶序列相关性。
    - 若 $\{\varepsilon_l\}$ 是独立同分布 iid 序列，$E\varepsilon_l^2 < \infin$，则$\sqrt n\hat\rho_l \sim N(0,1)$.
    - 混成检验：$Q^*(m)=n\sum\limits^m_{l=1}\hat\rho_l^2$，检验某几个自相关系数是否同时为0。$\hat\rho_l$ 是间隔为 $l$ 的样本自相关系数。
    - LB检验：将 $Q^*(m)$ 修改为 $Q(m)=T(T+2)\sum\limits^m_{l=1}\frac{\hat \rho^2_l}{T-l}$. 与对应 $\chi_\alpha^2$ 比较，具体略，见PPT/视频。



## 0516 Box-Cox变换与异方差检验

- Box-Cox变换的作业都做过了，详细的不写了

- 异方差检验

  - 在异方差线性回归模型的一般形式下：（G是每一项异方差组成的对角矩阵）

  $$
  Y=X\beta+\varepsilon,\ E[\varepsilon|X]=0,\ \varepsilon|X \sim N(0,G), G \neq \sigma^2_1I_n > 0
  $$

  ​		这个模型的 OLS 估计量是 $\hat \beta_{OLS}=(X^\top X)^{-1}X^\top Y$，依然满足无偏估计、强一致估计，但它的方差不再是最小方差，估计不稳定。如前所述，F 统计量和 t 统计量也不再服从 F 分布和 t 分布。

  - ==**德菲尔德和昆茨异方差检验**==的异方差修正模型：假定 $\sigma_i=\phi_i\sigma$. 下面分别反映 $\phi_i$ 已知和未知的情况，$x_k$为异方差因子。

  $$
  \sigma_i=\phi_i\sigma
  \\ Y_i/\phi_i=\beta_0/\phi_i+\sum\limits^k_{j=1}\beta_j X_{i,j}/\phi_i+u_i,\ E[u_i|X_i]=0, u_i=\varepsilon_i/
  \phi_i
  \\ \sigma_i=f(X_{ik})=X_{ik}^2\sigma^2
  \\ Y_i/X_{ik}=\beta_0/X_{ik}+\sum\limits^k_{j=1}\beta_j X_{i,j}/X_{ik}+\varepsilon_i/X_{ik},\ E[\varepsilon_i|X_i]=0.
  $$

  ​		假设检验问题是 $\sigma_1=\sigma_2= \dots =\sigma_n$ 是否成立。具体的步骤见PPT/视频。

  - 布莱茨和帕根（1979）则引入了外生的变量。

  $$
  Y_i=\beta_0+\sum\limits^k_{j=1}\beta_jX_{i,j}+\varepsilon_i,\ E[\varepsilon_i|X_i]=0, \ 
  \\ \sigma_i^2=f(a+\gamma^\tau Z_i), Z_i=(Z_{i1}, \dots, Z_{ip})^\tau, p \geq 1, 1 \leq i \leq n.
  \\ *\ f(a+\gamma^\tau Z_i)= a+\gamma^\tau Z_i, \varepsilon_i^2 = a+\gamma^\tau Z_i+u_i, 1 \leq i \leq n.
  $$

  ​		其中 $f$ 是一个泛函，$Z_i$ 是异方差因子向量。在简单的线性函数$(*)$下，可以简单地刻画 $\sigma_i^2$ 的变化。假设检验问题是$\gamma\ ?=0$.



## 0520 更多异方差检验方法

- 布莱茨和帕根在模型中附加了波动方程。具体见PPT/视频。

- 怀特异方差检验 White's Heteroskedasticity Test
  $$
  \sigma_i^2=f(a+\gamma^\tau Z_i), Z_i=(Z_{i1}, \dots, Z_{ip})^\tau, p \geq 1.
  \\ \varepsilon_i^2 = a+Z_i^\tau\gamma+v_i, 1 \leq i \leq n.
  \\ nR^2 \sim \chi^2(p)
  $$
  检验统计量为 $nR^2$.

- 线性回归模型的异方差修正与==**广义最小二乘法（GOLS）**==

  - 一个一般的模型是：其中 $G$ 的估计很重要。

  $$
  Y=X\beta+\varepsilon,\ E[\varepsilon|X]=0,\ \varepsilon|X \sim N(0, \sigma^2G), G >0.
  $$


  - $G$ 已知情况下，可以令 $\tilde X=G^{-1/2}X, \tilde\varepsilon=G^{-1/2}\varepsilon$. 从而得到新的模型 $Z=G^{-1/2}Y=\tilde X\beta+\tilde\varepsilon,\ \varepsilon im N(0, \sigma^2I_m)$.

    得到估计量 $\hat \beta_{GOLS}=(\tilde X^\top\tilde X)^{-1}\tilde X^\top Z=(X^\top G^{-1} X)^{-1} X^\top G^{-1} Y$，估计的因变量$\tilde Y=G^{1/2}\tilde Z=X\tilde\beta_{GOLS}$.

    $\hat \beta_{GOLS}$ 具有优良性质：无偏性、正态性、一致估计、最小方差无偏估计，可用 F 和 T 检验。

  - G未知条件下：（具体见PPT/视频）

    1. 假设随机干扰序列 $\{\varepsilon_i\}_1^n$ 是一个平稳的 $AR(1)$ 序列可以得到一个估计。
    2. 假设线性回归模型经检验存在显著异方差，可以采用德菲尔德和昆茨、布莱茨和帕根的加权最小二乘法（WOLS），和怀特检验。



## 0527 异方差线性模型的参数估计和多重共线性

- 正态随机干扰下的参数估计：直接采用 $\hat\beta_{OLS}$ ，具有无偏性、异质性、渐近正态性、渐近MVUE（最小方差无偏估计）等性质。
  - 正态随机干扰下的异方差模型参数检验：Z检验和t检验。（具体见PPT/视频）
  - 拟极大似然估计、拟极大似然法(QLM)，采用正态对数拟似然函数，（具体见PPT/视频）。得到的估计量 $\hat\beta_{QLME}$ 在正态随机干扰下与 $\hat\beta_{OLS}$ 相同，且具有相似的性质。在非正态随机干扰下不相同。
  - AIC和BIC信息准则：具体见PPT/视频。

- ==**多重共线性问题**==：$rank(X)<k+1$. 此时 $Y=X\hat\beta$ 不再是 $X\beta$ 的MVUE。
  - 多重共线性的诊断：
    1. 考察样本两项 $X_i \& X_j$ 的相关系数 $\bar\rho_{i,j}$ 分析方法，如果样本的相关系数过大，存在多重共线性。
    2. 条件 $\phi$ 检验，存在多重共线性的模型是病态模型，可以找到酉矩阵 $U, U^\top U=UU^\top=I_{k+1}$. （具体见PPT/视频）



## 0603 更多多重共线性讨论，与内生性问题

- 计算 $X^\top X$ 的特征根的大小，从而判断线性模型的病态性。可以求得 $\beta_i$ 的方差膨胀系数 $VIF:=Var(\beta_i|X_{n})=\eta_{i+1,i+1}\sigma^2, 0 \leq i \leq k$.

  如果 $VIF$ 越大（经验大于10），模型的病态性/共线性就越严重。还可以计算膨胀系数贡献矩阵 $P=(p_{ij})_{(k+1) \times (k+1)}$（具体见PPT/视频）

- 条件 $\phi$ 检验，$\phi=\frac{\lambda_{max}}{\lambda_{min}}$. 经验认为 $\phi > 1000$ 则未回归。

- ==**岭回归**==的诊断方法：取实数 $\tau > 0$，考虑模型的一个损失函数
  $$
  L(\beta, \tau)=(Y-X\beta)^\top(Y-X\beta)+\tau\beta^\top\beta=||Y-X\beta||^2+\tau||\beta||^2
  \\ F.O.C. \ \ (X^\top X+\tau I)\beta=X^\top Y
  \\ \beta^*=(X^\top X+\tau I)^{-1}X^\top Y
  $$
  $\beta^*$ 为参数 $\beta$ 的岭回归估计，$\tau$ 为岭回归参数，需要尽可能小。依然使用找酉矩阵的方式计算 $Var(\beta^*|X)$，使其满足 $VIF$ 的限制。

- ==**内生性问题**==：$Cov(X,\varepsilon) \neq 0$，则至少存在一个内生变量 $X_j$ 使得 $Cov(X_j, \varepsilon) \neq 0$. 此时得到的估计量 $\hat\beta$ 不具备正态性、不是线性无偏估计、F 检验和 T 检验不成立，会导致存在内生变量偏差。

- ==**工具变量方法**==：介绍了两种情况，包括弱工具变量，可以得到 $\gamma$ 的强有效估计。



## 0610 to be continued...
